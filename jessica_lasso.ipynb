{
 "metadata": {
  "name": "",
  "signature": "sha256:6c446fcec451210d3f263de3d773db89e7000a2bf7e993e1d76f3b90e8cbfaf3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from cvxopt import matrix\n",
      "from cvxpy import *\n",
      "import numpy as np\n",
      "import cvxopt\n",
      "from multiprocessing import Pool\n",
      "import sys\n",
      "\n",
      "word_list = []\n",
      "word_count_matrix = []\n",
      "document = []\n",
      "b = []\n",
      "results = []\n",
      "\n",
      "count = 0\n",
      "\n",
      "# To change\n",
      "query = 'brain'\n",
      "\n",
      "print \"Query word is \" + query\n",
      "\n",
      "# Making word list\n",
      "with open('wordlist.csv') as csvfile:\n",
      "    word_list_file = csv.reader(csvfile, delimiter=',')\n",
      "    for row in word_list_file:\n",
      "        if count < 100:\n",
      "            word_list.append(row[0].lower())\n",
      "            count += 1\n",
      "\n",
      "# Making bag of words matrix\n",
      "with open('category.csv') as csvfile:\n",
      "    category_file = csv.reader(csvfile, delimiter=',')\n",
      "    for row in category_file:\n",
      "        document = row[0].lower()\n",
      "        matrix_row = []\n",
      "        for word in word_list:\n",
      "            matrix_row.append(document.count(word, 0))\n",
      "        word_count_matrix.append(matrix_row)\n",
      "\n",
      "word_index = word_list.index(query)\n",
      "for i in range(len(word_count_matrix)):\n",
      "    if word_count_matrix[i][word_index] == 0:\n",
      "        b.append(-1)\n",
      "    else:\n",
      "        b.append(1)\n",
      "    word_count_matrix[i].pop(word_index)  # Leave one out\n",
      "\n",
      "\n",
      "# Problem data.\n",
      "n = len(word_count_matrix)  # Number of documents\n",
      "m = 100 - 1  # Number of words\n",
      "A = matrix(word_count_matrix).trans()\n",
      "b = matrix(b)\n",
      "gamma = Parameter(sign=\"positive\")\n",
      "\n",
      "# Construct the problem.\n",
      "x = Variable(m)\n",
      "objective = Minimize(sum_squares(A * x - b) + gamma * norm(x, 1))\n",
      "p = Problem(objective)\n",
      "\n",
      "# Assign a value to gamma and find the optimal x.\n",
      "\n",
      "\n",
      "def get_x(gamma_value):\n",
      "    gamma.value = gamma_value\n",
      "    result = p.solve()\n",
      "    return x.value\n",
      "\n",
      "gammas = np.logspace(-1, 2, num=100)\n",
      "# Serial computation.\n",
      "x_values = [get_x(value) for value in gammas]\n",
      "\n",
      "# Parallel computation.\n",
      "pool = Pool(processes=4)\n",
      "par_x = pool.map(get_x, gammas)\n",
      "\n",
      "print \"Computing the problem\"\n",
      "for v1, v2 in zip(x_values, par_x):\n",
      "    if np.linalg.norm(v1 - v2) > 1e-5:\n",
      "        print \"error\"\n",
      "\n",
      "sorted_x = sorted(x_values[0], reverse=True)\n",
      "word_result = []\n",
      "for i in range(10):\n",
      "    for index in range(len(x_values[0])):\n",
      "        if x_values[0][index] == sorted_x[i]:\n",
      "            word_result.append(word_list[index])\n",
      "        if len(word_result) == 10:\n",
      "            break\n",
      "    #Redundant but not sure how else to break\n",
      "    if len(word_result) == 10:\n",
      "            print word_result\n",
      "            break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query word is brain\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Computing the problem\n",
        "['dynamical', 'networks', 'born', 'uncover', 'neuronal', 'animals', 'recognize', 'odors', 'stages', 'hawkmoth']\n"
       ]
      }
     ],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}