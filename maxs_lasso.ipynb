{
 "metadata": {
  "name": "",
  "signature": "sha256:cfbcfb5a74897eeab02f52634d841ccc856b3cd74b33938a6e16f4f21558db24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################\n",
      "# Creates a term document matrix from movie reviews data          #\n",
      "###################################################################\n",
      "import sys\n",
      "import os\n",
      "import glob\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "START_K = 0\n",
      "K = 200\n",
      "\n",
      "# Movie data corpus\n",
      "negative_files = glob.glob(\"movie_review_data/neg/*.txt\")\n",
      "positive_files = glob.glob(\"movie_review_data/pos/*.txt\")\n",
      "all_file_names = negative_files + positive_files\n",
      "\n",
      "# Load valid english words\n",
      "valid_words = set()\n",
      "dictionary_file = open(\"words\")\n",
      "for word in dictionary_file:\n",
      "    word = word.lower().strip()\n",
      "    valid_words.add(word)\n",
      "    \n",
      "# Load english stop words\n",
      "stop_words = set()\n",
      "stop_words_file = open(\"stop_words\")\n",
      "for word in stop_words_file:\n",
      "    word = word.lower().strip()\n",
      "    stop_words.add(word)\n",
      "\n",
      "# Filter even more. Only take the K top most frequent words from the combined corpus\n",
      "word_frequencies = {}\n",
      "corpus_words = set()\n",
      "for file_name in all_file_names:\n",
      "    f = open(file_name)\n",
      "    text = unicode(f.read(), 'latin-1')\n",
      "    for word in text.split(\" \"):\n",
      "        word = word.lower().strip()\n",
      "        if word in valid_words and word not in stop_words:\n",
      "            if word not in word_frequencies:\n",
      "                word_frequencies[word] = 0\n",
      "            word_frequencies[word] += 1\n",
      "            corpus_words.add(word)\n",
      "    f.close()\n",
      "valid_features = sorted(corpus_words, key=lambda x: word_frequencies[x], reverse=True)[START_K:START_K+K]\n",
      "                \n",
      "# Collect all movie review text (both positive and negatively sentimented)\n",
      "corpus = []\n",
      "for count, file_name in enumerate(all_file_names):\n",
      "    f = open(file_name)\n",
      "    document_string = unicode(f.read(), 'latin-1')\n",
      "    filtered_document_string = \"\"\n",
      "    for word in document_string.split(\" \"):\n",
      "        word = word.lower().strip()\n",
      "        if word in valid_features:\n",
      "            filtered_document_string += word + ' '\n",
      "    corpus.append(filtered_document_string)\n",
      "    f.close()\n",
      "print(\"Done creating corpus!\")\n",
      "\n",
      "# Use Sklearn to get the term document matrix\n",
      "vectorizer = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
      "term_doc_matrix = vectorizer.fit_transform(corpus)\n",
      "\n",
      "# tdm and features\n",
      "tdm = term_doc_matrix.toarray()\n",
      "features = vectorizer.get_feature_names()\n",
      "\n",
      "print(\"Number of rows: %d cols: %d\" % tdm.shape)\n",
      "print(tdm)\n",
      "print(\"Features:\")\n",
      "print(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done creating corpus!\n",
        "Number of rows: 1400 cols: 191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.          0.09493509  0.09173926 ...,  0.          0.          0.        ]\n",
        " [ 0.          0.          0.07059803 ...,  0.          0.06947842  0.        ]\n",
        " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " ..., \n",
        " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " [ 0.08754548  0.          0.06867588 ...,  0.08877089  0.          0.        ]]\n",
        "Features:\n",
        "[u'able', u'acting', u'action', u'actor', u'actually', u'alien', u'american', u'audience', u'bad', u'based', u'believe', u'bit', u'black', u'book', u'boring', u'boy', u'camera', u'car', u'care', u'cast', u'character', u'city', u'comedy', u'comes', u'comic', u'completely', u'couple', u'course', u'dark', u'daughter', u'david', u'day', u'days', u'dead', u'death', u'deep', u'despite', u'dialogue', u'directed', u'direction', u'director', u'doing', u'drama', u'effects', u'entertaining', u'entire', u'especially', u'evil', u'exactly', u'example', u'family', u'father', u'feel', u'film', u'final', u'finally', u'friend', u'fun', u'funny', u'game', u'getting', u'girl', u'goes', u'guy', u'half', u'hand', u'hard', u'head', u'help', u'hit', u'hollywood', u'home', u'horror', u'hour', u'house', u'human', u'humor', u'idea', u'instead', u'jack', u'james', u'job', u'joe', u'john', u'kevin', u'kids', u'language', u'lee', u'left', u'life', u'line', u'little', u'live', u'look', u'looking', u'lost', u'lot', u'love', u'main', u'matter', u'maybe', u'michael', u'mind', u'moment', u'money', u'mother', u'movie', u'music', u'nearly', u'nice', u'night', u'novel', u'obvious', u'original', u'past', u'paul', u'people', u'perfect', u'performance', u'person', u'peter', u'picture', u'play', u'plot', u'pretty', u'probably', u'production', u'rated', u'real', u'reason', u'relationship', u'rest', u'review', u'robert', u'role', u'run', u'running', u'scene', u'school', u'scream', u'screen', u'screenplay', u'script', u'seeing', u'seen', u'sense', u'sequence', u'series', u'set', u'sex', u'short', u'shot', u'simply', u'son', u'soon', u'special', u'star', u'starring', u'start', u'story', u'strong', u'style', u'summer', u'supporting', u'supposed', u'tell', u'time', u'times', u'title', u'tom', u'town', u'true', u'truly', u'try', u'trying', u'unfortunately', u'van', u'video', u'violence', u'visit', u'war', u'watch', u'watching', u'white', u'wife', u'woman', u'world', u'worst', u'worth', u'written', u'wrong']\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################\n",
      "# Searches query term within list of corpus                       #\n",
      "###################################################################\n",
      "\n",
      "query = unicode('performance')\n",
      "query_presence_indicators = []\n",
      "\n",
      "# Create the indicator column\n",
      "if query in features:\n",
      "    location_in_matrix = features.index(query)\n",
      "    features.remove(query)\n",
      "    \n",
      "    # Remove column with query term from tdm\n",
      "    tdm = np.delete(tdm, location_in_matrix, axis=1)\n",
      "    \n",
      "    # Construct indicator vector\n",
      "    for document in tdm:\n",
      "        if document[location_in_matrix] != 0:\n",
      "            query_presence_indicators.append(1)\n",
      "        else:\n",
      "            query_presence_indicators.append(-1)\n",
      "else:\n",
      "    print(\"Query not found\")\n",
      "\n",
      "print(\"Number of documents\", len(query_presence_indicators))\n",
      "print(\"Number of times query appears in all documents: \", sum([1 if x == 1 else 0 for x in query_presence_indicators]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Number of documents', 1400)\n",
        "('Number of times query appears in all documents: ', 183)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cvxpy import *\n",
      "import numpy as np\n",
      "import cvxopt\n",
      "from multiprocessing import Pool\n",
      "\n",
      "# Problem data.\n",
      "A = tdm\n",
      "b = query_presence_indicators\n",
      "gamma = Parameter(sign=\"positive\")\n",
      "\n",
      "# Construct the problem.\n",
      "x = Variable(len(A[0]))\n",
      "objective = Minimize(sum_squares(A*x - b) + gamma*norm(x, 1))\n",
      "p = Problem(objective)\n",
      "\n",
      "# Assign a value to gamma and find the optimal x.\n",
      "def get_x(gamma_value):\n",
      "    gamma.value = gamma_value\n",
      "    result = p.solve()\n",
      "    return x.value\n",
      "\n",
      "gammas = np.logspace(-1, 2, num=100)\n",
      "\n",
      "# Parallel computation.\n",
      "print(\"Starting computation\")\n",
      "pool = Pool(processes=1)\n",
      "x_values = pool.map(get_x, gammas)\n",
      "\n",
      "# Serial computation.\n",
      "lasso_weights = [get_x(value) for value in gammas]\n",
      "\n",
      "for v1,v2 in zip(x_values, lasso_weights):\n",
      "    if np.linalg.norm(v1 - v2) > 1e-5:\n",
      "        print \"error\"\n",
      "        \n",
      "print(\"Done!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting computation\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done!\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright (c) 2014 Steve Yadlowsky, Preetum Nakkarin.\n",
      "# Licensed under MIT License.\n",
      "# More information including the exact terms of the License\n",
      "# can be found in the file COPYING in the project root directory.\n",
      "\n",
      "import numpy as np\n",
      "import time\n",
      "import operator\n",
      "import scipy.sparse\n",
      "\n",
      "class IHTClassifier(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.training_time = 0.0\n",
      "        self.beta = None\n",
      "\n",
      "    def card(self, x):\n",
      "        return np.sum(x != 0)\n",
      "\n",
      "    def train(self, X, y, card=100, verbose=False):\n",
      "        start = time.time()\n",
      "        if verbose:\n",
      "            print \"Preconditioning matrix\"\n",
      "        whitened_X, feature_avg = self.whiten_features(X)\n",
      "        lsv = float(self.compute_lsv(whitened_X, feature_avg))\n",
      "        if verbose:\n",
      "            print \"Matching pursuits\"\n",
      "        x_hat = self.matching_pursuit_sparse(y, whitened_X/lsv, feature_avg/lsv, card)\n",
      "        if verbose:\n",
      "            print \"Running iterative hard thresholding\"\n",
      "        self.beta = self.AIHT_sparse(y, whitened_X/lsv, x_hat, card, feature_avg/lsv)/lsv\n",
      "\n",
      "        self.training_time += time.time() - start\n",
      "\n",
      "    def whiten_features(self, X):\n",
      "        X = X.tocsr(copy=True)\n",
      "        row_avg = np.bincount(X.indices, weights=X.data)\n",
      "        row_avg /= float(X.shape[0])\n",
      "        row_norm = np.bincount(X.indices, weights=(X.data - row_avg[X.indices])**2)\n",
      "        nonzeros_in_each_column = np.diff(X.tocsc().indptr)\n",
      "        avg_norm = ((float(X.shape[0])*np.ones(X.shape[1])) - nonzeros_in_each_column)*(row_avg**2)\n",
      "        row_norm += avg_norm\n",
      "        row_norm = np.array([np.sqrt(x) if x != 0 else 1 for x in row_norm])\n",
      "        row_avg /= row_norm\n",
      "        X.data /= np.take(row_norm, X.indices)\n",
      "        feature_avg = np.squeeze(row_avg)\n",
      "\n",
      "        return X, feature_avg\n",
      "\n",
      "    def compute_lsv(self, X, feature_avg):\n",
      "        def matmuldyad(v):\n",
      "            return X.dot(v) - feature_avg.dot(v)\n",
      "\n",
      "        def rmatmuldyad(v):\n",
      "            return X.T.dot(v) - v.sum()*feature_avg\n",
      "        normalized_lin_op = scipy.sparse.linalg.LinearOperator(X.shape, matmuldyad, rmatmuldyad)\n",
      "\n",
      "        def matvec_XH_X(v):\n",
      "            return normalized_lin_op.rmatvec(normalized_lin_op.matvec(v))\n",
      "\n",
      "        which='LM'\n",
      "        v0=None\n",
      "        maxiter=None\n",
      "        return_singular_vectors=False\n",
      "\n",
      "        XH_X = scipy.sparse.linalg.LinearOperator(matvec=matvec_XH_X, dtype=X.dtype, shape=(X.shape[1], X.shape[1]))\n",
      "        eigvals = scipy.sparse.linalg.eigs(XH_X, k=1, tol=0, maxiter=None, ncv=10, which=which, v0=v0, return_eigenvectors=False)\n",
      "        lsv = np.sqrt(eigvals)\n",
      "        return lsv[0].real\n",
      "\n",
      "    def matching_pursuit_sparse(self, y, X, feature_avg, k, tol=10**-10):\n",
      "        '''\n",
      "        Matching Pursuit\n",
      "        '''\n",
      "        r = y\n",
      "        X = X.tocsc()\n",
      "        err_norm = np.linalg.norm(r, 2)\n",
      "        err_norm_prev = 0\n",
      "        beta = np.zeros(X.shape[1])\n",
      "        while self.card(beta) < k:\n",
      "            all_inner_products = X.T.dot(r) - np.sum(r)*feature_avg\n",
      "            max_index, max_abs_inner_product = max(enumerate(np.abs(all_inner_products)), key=operator.itemgetter(1))\n",
      "            g = X[:, max_index]\n",
      "            g = np.squeeze(np.asarray(g.todense())) - feature_avg[max_index]\n",
      "            a = all_inner_products[max_index]\n",
      "            a /= np.linalg.norm(g, 2)**2\n",
      "            beta[max_index] += a\n",
      "            r = r - a*g\n",
      "            err_norm_prev = err_norm\n",
      "            err_norm = np.linalg.norm(r, 2)\n",
      "            if np.abs(err_norm - err_norm_prev) <= tol:\n",
      "                break\n",
      "        return beta\n",
      "\n",
      "    def thresholder(self, y,m):\n",
      "        sort_y = sorted(np.abs(y))\n",
      "        thresh = sort_y[-m]\n",
      "\n",
      "        non_thresholded_indices = (np.abs(y) > thresh)\n",
      "        n_nonzero_indices = sum(non_thresholded_indices)\n",
      "        if n_nonzero_indices < m:\n",
      "            collisions = np.where((np.abs(y)==thresh))[0]\n",
      "            passed = np.random.choice(collisions,m-n_nonzero_indices)\n",
      "            non_thresholded_indices[passed] = 1\n",
      "\n",
      "        y_new = non_thresholded_indices * y\n",
      "\n",
      "        return y_new, thresh\n",
      "\n",
      "    def AIHT_sparse(self, y, X, beta, k, feature_avg=None, alpha=0, example_weights=None, max_iters=10000, tol=10**-16):\n",
      "        \"\"\"Solves DORE accelerated IHT with a sparse matrix X.\n",
      "        \"\"\"\n",
      "        m, n = X.shape\n",
      "        y = np.squeeze(np.asarray(y))\n",
      "        err_norm_prev = 0\n",
      "        beta_0 = beta\n",
      "        beta_prev = beta\n",
      "        X_beta = 0\n",
      "        X_beta_prev = 0\n",
      "        X_beta_twice_prev = 0\n",
      "\n",
      "        if feature_avg is None:\n",
      "            feature_avg = np.zeros(n)\n",
      "    \n",
      "        if example_weights is None:\n",
      "            example_weights = np.ones(m)\n",
      "    \n",
      "        for iter_ in xrange(max_iters):\n",
      "            X_beta_twice_prev = X_beta_prev\n",
      "            X_beta_prev = X_beta\n",
      "            X_beta = (X.dot(beta) - feature_avg.dot(beta))\n",
      "            X_beta = np.squeeze(np.asarray(X_beta))\n",
      "            err = y - example_weights*X_beta\n",
      "            err_reg = -alpha*beta\n",
      "            norm_change = ((np.linalg.norm(beta - beta_prev)**2)/n)\n",
      "            print err.dot(err) + err_reg.dot(err_reg), norm_change, np.linalg.norm(beta)\n",
      "\n",
      "            if iter_ > 0 and (norm_change <= tol):\n",
      "                break\n",
      "\n",
      "            beta_t = beta + np.squeeze(np.asarray(X.T.dot(err))) - err.sum()*feature_avg + alpha*err_reg\n",
      "            beta_t = np.squeeze(np.asarray(beta_t))\n",
      "    \n",
      "            beta_t, thresh = self.thresholder(beta_t,k)\n",
      "            X_beta = X.dot(beta_t) - feature_avg.dot(beta_t)\n",
      "            X_beta = np.squeeze(X_beta)\n",
      "            err = y - example_weights*X_beta\n",
      "            err_reg = -alpha*beta_t\n",
      "    \n",
      "            beta_t_star = beta_t\n",
      "            if iter_ > 2:\n",
      "                delta_X_beta = X_beta - X_beta_prev\n",
      "                delta_regularization = alpha*(beta_t - beta)\n",
      "                dp = delta_X_beta.dot(example_weights*delta_X_beta) + delta_regularization.dot(delta_regularization)\n",
      "                if dp > 0:\n",
      "                    a1 = (delta_X_beta.dot(err) + delta_regularization.dot(err_reg))/dp\n",
      "                    X_beta_1 = (1+a1)*X_beta - a1*X_beta_prev\n",
      "                    beta_1 = beta_t + a1*(beta_t - beta)\n",
      "                    err_1 = y - example_weights*X_beta_1\n",
      "                    err_1_reg = -alpha*beta_1\n",
      "    \n",
      "                    delta_X_beta = X_beta_1 - X_beta_twice_prev\n",
      "                    delta_regularization = alpha*(beta_1 - beta_prev)\n",
      "                    dp = delta_X_beta.dot(example_weights*delta_X_beta) + delta_regularization.dot(delta_regularization)\n",
      "                    if dp > 0:\n",
      "                        a2 = (delta_X_beta.dot(err_1) + delta_regularization.dot(err_1_reg))/dp\n",
      "                        beta_2 = beta_1 + a2*(beta_1 - beta_prev)\n",
      "                        beta_2, thresh = self.thresholder(beta_2,k)\n",
      "    \n",
      "                        X_beta_2 = X.dot(beta_2) - feature_avg.dot(beta_2)\n",
      "                        X_beta_2 = np.squeeze(np.asarray(X_beta_2))\n",
      "                        err_2 = y - example_weights*X_beta_2\n",
      "                        err_reg_2 = -alpha*beta_2\n",
      "    \n",
      "                        if (err_2.dot(err_2) + err_reg_2.dot(err_reg_2)) / (err.dot(err) + err_reg.dot(err_reg)) < 1:\n",
      "                            beta_t_star = beta_2\n",
      "                            X_beta = X_beta_2\n",
      "    \n",
      "            beta_prev = beta\n",
      "            beta = beta_t_star\n",
      "    \n",
      "        return beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = IHTClassifier()\n",
      "sparse_matrix = scipy.sparse.csr_matrix(A)\n",
      "classifier.train(sparse_matrix, b, verbose=True)\n",
      "IHT_weights = classifier.beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Preconditioning matrix\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "878.894382139 0.0 38.4410879916\n",
        "878.696318756 0.000620034088705 38.4917322776\n",
        "878.598520156 0.000298128897877 38.5327501757\n",
        "878.544709687 0.000161101379075 38.5652448116\n",
        "878.463777032 0.00189346044782 38.6833176686\n",
        "878.456256437 0.000151891843922 38.6937038264\n",
        "878.455445651 1.36450608258e-05 38.6905734643\n",
        "878.455362441 1.3761299162e-06 38.6905644141\n",
        "878.455353372 1.44762637708e-07 38.6906042604\n",
        "878.455352494 1.28730518664e-08 38.6901848222\n",
        "878.455352386 1.47189519819e-09 38.6900998878\n",
        "878.455352375 1.8961170578e-10 38.6901006923\n",
        "878.455352374 1.35133498343e-11 38.6901052813\n",
        "878.455352374 3.16926517922e-12 38.6901042934\n",
        "878.455352374 3.22193136641e-13 38.6901045911\n",
        "878.455352374 4.51511088011e-14 38.6901044886\n",
        "878.455352374 1.02159287422e-14 38.6901045524\n",
        "878.455352374 1.43974691231e-16 38.6901045589\n",
        "878.455352374 4.49885283092e-17 38.6901045631\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################\n",
      "# Sorts words by their weights of the above computed portion                       #\n",
      "####################################################################################\n",
      "\n",
      "print(\"IHT Keywords\")\n",
      "all_terms = [(x, IHT_weights[i]) for i, x in enumerate(features)]\n",
      "all_terms.sort(key=lambda x: x[1], reverse=True)\n",
      "print([x[0] for x in all_terms[:20]])\n",
      "\n",
      "print(\"Lasso Keywords\")\n",
      "for weights in lasso_weights:\n",
      "    all_terms = [(x, weights[i]) for i, x in enumerate(features)]\n",
      "    all_terms.sort(key=lambda x: x[1], reverse=True)\n",
      "    print([x[0] for x in all_terms[:20]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "IHT Keywords\n",
        "[u'person', u'scream', u'care', u'tom', u'film', u'paul', u'jack', u'couple', u'nearly', u'able', u'john', u'music', u'effects', u'character', u'strong', u'joe', u'main', u'original', u'scene', u'world']\n",
        "Lasso Keywords\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'mind', u'violence', u'instead', u'screenplay', u'written']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'mind', u'instead', u'screenplay', u'written']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'mind', u'instead', u'screenplay', u'written']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'mind', u'instead', u'screenplay', u'written']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'mind', u'instead', u'screenplay', u'written']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'screenplay', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'screenplay', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'finally', u'character', u'scream', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'screenplay', u'scene']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'character', u'finally', u'scream', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'scene', u'screenplay']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'character', u'finally', u'scream', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'scene', u'screenplay']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'character', u'scream', u'finally', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'character', u'scream', u'finally', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'music', u'character', u'scream', u'finally', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'character', u'music', u'scream', u'finally', u'obvious', u'couple', u'rated', u'violence', u'instead', u'mind', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'rated', u'instead', u'mind', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'rated', u'instead', u'mind', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'rated', u'mind', u'instead', u'scene', u'comes']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'rated', u'mind', u'instead', u'scene', u'trying']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'rated', u'instead', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'instead', u'rated', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'instead', u'rated', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'instead', u'scene', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'instead', u'scene', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'violence', u'couple', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'tell', u'strong', u'paul', u'scream', u'character', u'music', u'finally', u'obvious', u'violence', u'couple', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'paul', u'tell', u'scream', u'strong', u'character', u'music', u'finally', u'obvious', u'violence', u'couple', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'strong', u'tell', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'strong', u'tell', u'character', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'scene', u'instead', u'rated', u'trying']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'strong', u'character', u'tell', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'strong', u'character', u'tell', u'music', u'finally', u'obvious', u'couple', u'violence', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'character', u'strong', u'tell', u'music', u'obvious', u'finally', u'violence', u'couple', u'mind', u'scene', u'instead', u'rated', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'character', u'strong', u'tell', u'music', u'finally', u'obvious', u'mind', u'violence', u'couple', u'rated', u'instead', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'supporting', u'main', u'scream', u'paul', u'character', u'strong', u'music', u'tell', u'finally', u'obvious', u'mind', u'violence', u'couple', u'rated', u'instead', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'main', u'supporting', u'scream', u'paul', u'character', u'strong', u'music', u'tell', u'finally', u'obvious', u'mind', u'violence', u'couple', u'rated', u'instead', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'main', u'supporting', u'scream', u'character', u'paul', u'strong', u'music', u'tell', u'finally', u'obvious', u'mind', u'violence', u'couple', u'rated', u'instead', u'scene', u'trying']\n",
        "[u'person', u'care', u'nearly', u'main', u'supporting', u'scream', u'character', u'paul', u'strong', u'music', u'tell', u'finally', u'obvious', u'mind', u'violence', u'couple', u'rated', u'instead', u'trying', u'scene']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'nearly', u'main', u'supporting', u'scream', u'character', u'paul', u'strong', u'tell', u'music', u'finally', u'mind', u'obvious', u'violence', u'couple', u'rated', u'instead', u'trying', u'scene']\n",
        "[u'person', u'care', u'nearly', u'main', u'supporting', u'scream', u'character', u'paul', u'strong', u'tell', u'music', u'finally', u'mind', u'obvious', u'violence', u'couple', u'rated', u'instead', u'able', u'trying']\n",
        "[u'person', u'care', u'nearly', u'main', u'scream', u'supporting', u'character', u'paul', u'strong', u'tell', u'music', u'mind', u'finally', u'obvious', u'couple', u'violence', u'rated', u'able', u'instead', u'trying']\n",
        "[u'person', u'care', u'nearly', u'scream', u'main', u'supporting', u'character', u'paul', u'strong', u'tell', u'music', u'mind', u'finally', u'obvious', u'couple', u'violence', u'rated', u'able', u'instead', u'trying']\n",
        "[u'person', u'care', u'nearly', u'scream', u'main', u'supporting', u'character', u'paul', u'strong', u'tell', u'music', u'mind', u'finally', u'obvious', u'couple', u'violence', u'rated', u'able', u'instead', u'try']\n",
        "[u'person', u'care', u'nearly', u'scream', u'main', u'supporting', u'character', u'strong', u'paul', u'tell', u'mind', u'music', u'finally', u'obvious', u'violence', u'couple', u'rated', u'able', u'try', u'idea']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'nearly', u'scream', u'main', u'supporting', u'strong', u'character', u'paul', u'tell', u'music', u'mind', u'finally', u'obvious', u'couple', u'violence', u'rated', u'able', u'try', u'idea']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'strong', u'character', u'tell', u'paul', u'music', u'mind', u'finally', u'obvious', u'couple', u'violence', u'rated', u'able', u'try', u'idea']\n",
        "[u'person', u'care', u'nearly', u'scream', u'main', u'supporting', u'strong', u'tell', u'character', u'paul', u'mind', u'music', u'finally', u'obvious', u'couple', u'violence', u'rated', u'able', u'try', u'idea']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'strong', u'tell', u'mind', u'character', u'paul', u'finally', u'music', u'obvious', u'couple', u'violence', u'able', u'rated', u'try', u'idea']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'strong', u'mind', u'tell', u'finally', u'paul', u'obvious', u'character', u'music', u'couple', u'violence', u'able', u'rated', u'try', u'completely']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'strong', u'mind', u'tell', u'finally', u'obvious', u'paul', u'music', u'character', u'couple', u'violence', u'able', u'rated', u'try', u'completely']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'strong', u'mind', u'tell', u'finally', u'obvious', u'paul', u'music', u'character', u'couple', u'violence', u'able', u'rated', u'try', u'completely']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'mind', u'strong', u'finally', u'tell', u'obvious', u'paul', u'music', u'character', u'able', u'couple', u'violence', u'rated', u'try', u'completely']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'mind', u'strong', u'tell', u'finally', u'obvious', u'paul', u'music', u'couple', u'able', u'violence', u'character', u'rated', u'completely', u'try']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'mind', u'strong', u'finally', u'tell', u'obvious', u'paul', u'music', u'able', u'couple', u'violence', u'character', u'try', u'completely', u'rated']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'mind', u'strong', u'finally', u'tell', u'obvious', u'music', u'paul', u'able', u'couple', u'violence', u'try', u'exactly', u'completely', u'rated']\n",
        "[u'person', u'care', u'nearly', u'scream', u'supporting', u'main', u'mind', u'strong', u'finally', u'tell', u'obvious', u'able', u'music', u'paul', u'couple', u'exactly', u'completely', u'violence', u'try', u'rated']\n",
        "[u'person', u'care', u'scream', u'supporting', u'main', u'nearly', u'tell', u'finally', u'mind', u'able', u'strong', u'jack', u'exactly', u'music', u'entire', u'try', u'violence', u'hour', u'completely', u'obvious']\n",
        "[u'person', u'care', u'scream', u'nearly', u'supporting', u'main', u'mind', u'finally', u'strong', u'obvious', u'tell', u'exactly', u'able', u'music', u'couple', u'completely', u'try', u'paul', u'violence', u'entire']\n",
        "[u'person', u'care', u'scream', u'nearly', u'supporting', u'main', u'mind', u'finally', u'strong', u'obvious', u'tell', u'exactly', u'completely', u'able', u'couple', u'try', u'music', u'paul', u'entire', u'idea']\n",
        "[u'person', u'care', u'scream', u'nearly', u'supporting', u'main', u'mind', u'finally', u'strong', u'obvious', u'tell', u'exactly', u'completely', u'able', u'couple', u'try', u'music', u'entire', u'idea', u'paul']\n",
        "[u'person', u'care', u'scream', u'nearly', u'supporting', u'mind', u'main', u'finally', u'strong', u'obvious', u'tell', u'exactly', u'completely', u'able', u'couple', u'try', u'music', u'entire', u'idea', u'paul']\n",
        "[u'person', u'care', u'scream', u'nearly', u'supporting', u'mind', u'main', u'finally', u'strong', u'obvious', u'tell', u'exactly', u'completely', u'able', u'couple', u'try', u'music', u'entire', u'idea', u'jack']\n",
        "[u'person', u'care', u'scream', u'supporting', u'nearly', u'mind', u'main', u'finally', u'strong', u'tell', u'obvious', u'exactly', u'completely', u'try', u'music', u'able', u'couple', u'entire', u'idea', u'jack']\n",
        "[u'person', u'care', u'scream', u'nearly', u'supporting', u'mind', u'finally', u'main', u'strong', u'obvious', u'tell', u'exactly', u'completely', u'able', u'try', u'couple', u'entire', u'music', u'idea', u'jack']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'supporting', u'finally', u'strong', u'obvious', u'exactly', u'main', u'tell', u'completely', u'able', u'try', u'couple', u'entire', u'idea', u'music', u'jack']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'supporting', u'finally', u'tell', u'strong', u'exactly', u'obvious', u'main', u'able', u'completely', u'try', u'couple', u'entire', u'music', u'idea', u'jack']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'supporting', u'finally', u'exactly', u'tell', u'strong', u'obvious', u'main', u'completely', u'able', u'try', u'couple', u'entire', u'music', u'idea', u'jack']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'supporting', u'finally', u'exactly', u'strong', u'tell', u'obvious', u'completely', u'able', u'main', u'try', u'couple', u'entire', u'music', u'idea', u'jack']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'finally', u'supporting', u'exactly', u'strong', u'tell', u'obvious', u'able', u'completely', u'main', u'try', u'couple', u'entire', u'music', u'idea', u'jack']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'finally', u'exactly', u'supporting', u'strong', u'tell', u'obvious', u'able', u'completely', u'try', u'main', u'couple', u'entire', u'hour', u'music', u'jack']\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'strong', u'tell', u'supporting', u'obvious', u'able', u'completely', u'try', u'main', u'entire', u'couple', u'hour', u'idea', u'music']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'exactly', u'finally', u'strong', u'tell', u'obvious', u'supporting', u'able', u'completely', u'try', u'main', u'entire', u'couple', u'idea', u'hour', u'reason']\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'strong', u'tell', u'obvious', u'able', u'completely', u'supporting', u'try', u'main', u'entire', u'hour', u'supposed', u'idea', u'reason']\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'strong', u'tell', u'obvious', u'able', u'completely', u'supporting', u'try', u'supposed', u'idea', u'entire', u'main', u'hour', u'reason']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'exactly', u'finally', u'tell', u'strong', u'obvious', u'able', u'completely', u'try', u'supporting', u'idea', u'supposed', u'entire', u'reason', u'main', u'start']\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'tell', u'strong', u'obvious', u'able', u'completely', u'try', u'supposed', u'idea', u'supporting', u'entire', u'reason', u'start', u'hour']\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'tell', u'strong', u'obvious', u'able', u'completely', u'try', u'supposed', u'idea', u'reason', u'entire', u'start', u'supporting', u'hour']\n",
        "[u'person', u'care', u'scream', u'nearly', u'mind', u'exactly', u'finally', u'tell', u'strong', u'obvious', u'able', u'completely', u'idea', u'supposed', u'try', u'entire', u'reason', u'start', u'main', u'horror']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'tell', u'strong', u'able', u'obvious', u'completely', u'supposed', u'idea', u'try', u'horror', u'reason', u'start', u'entire', u'boring']\n",
        "[u'person', u'care', u'scream', u'mind', u'nearly', u'exactly', u'finally', u'tell', u'strong', u'able', u'obvious', u'idea', u'supposed', u'completely', u'horror', u'try', u'reason', u'entire', u'start', u'boring']\n",
        "[u'person', u'scream', u'care', u'mind', u'nearly', u'exactly', u'finally', u'tell', u'strong', u'able', u'obvious', u'supposed', u'horror', u'idea', u'completely', u'try', u'boring', u'reason', u'start', u'entire']\n",
        "[u'person', u'scream', u'care', u'mind', u'nearly', u'exactly', u'finally', u'tell', u'strong', u'able', u'obvious', u'horror', u'idea', u'supposed', u'completely', u'try', u'reason', u'entire', u'start', u'boring']\n",
        "[u'person', u'scream', u'care', u'mind', u'exactly', u'nearly', u'tell', u'finally', u'horror', u'strong', u'able', u'idea', u'obvious', u'supposed', u'try', u'reason', u'completely', u'entire', u'boring', u'start']\n",
        "[u'person', u'scream', u'care', u'mind', u'exactly', u'tell', u'nearly', u'finally', u'horror', u'supposed', u'able', u'idea', u'strong', u'obvious', u'try', u'reason', u'entire', u'completely', u'boring', u'start']\n",
        "[u'person', u'scream', u'care', u'mind', u'exactly', u'tell', u'nearly', u'finally', u'horror', u'able', u'idea', u'supposed', u'strong', u'obvious', u'try', u'reason', u'entire', u'completely', u'boring', u'example']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'scream', u'care', u'mind', u'finally', u'strong', u'couple', u'tell', u'able', u'exactly', u'jack', u'nearly', u'obvious', u'supporting', u'try', u'music', u'idea', u'despite', u'main', u'entire']\n",
        "[u'person', u'scream', u'care', u'exactly', u'mind', u'tell', u'finally', u'horror', u'nearly', u'idea', u'supposed', u'able', u'strong', u'obvious', u'reason', u'try', u'entire', u'shot', u'boring', u'example']\n",
        "[u'person', u'scream', u'care', u'exactly', u'mind', u'tell', u'finally', u'horror', u'nearly', u'idea', u'supposed', u'able', u'strong', u'obvious', u'reason', u'try', u'entire', u'shot', u'example', u'style']\n",
        "[u'person', u'scream', u'care', u'exactly', u'mind', u'tell', u'horror', u'finally', u'nearly', u'supposed', u'idea', u'able', u'strong', u'obvious', u'reason', u'try', u'entire', u'shot', u'boring', u'example']\n",
        "[u'person', u'scream', u'care', u'exactly', u'mind', u'finally', u'tell', u'nearly', u'horror', u'idea', u'able', u'strong', u'supposed', u'obvious', u'reason', u'entire', u'main', u'try', u'shot', u'couple']\n",
        "[u'person', u'scream', u'care', u'exactly', u'horror', u'mind', u'finally', u'tell', u'idea', u'supposed', u'nearly', u'able', u'strong', u'wrong', u'obvious', u'shot', u'reason', u'entire', u'style', u'example']\n",
        "[u'person', u'scream', u'care', u'exactly', u'mind', u'horror', u'finally', u'tell', u'nearly', u'idea', u'supposed', u'able', u'strong', u'obvious', u'reason', u'shot', u'wrong', u'entire', u'try', u'example']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'scream', u'care', u'exactly', u'mind', u'finally', u'tell', u'horror', u'idea', u'nearly', u'supposed', u'able', u'strong', u'obvious', u'reason', u'shot', u'wrong', u'entire', u'couple', u'main']\n",
        "[u'person', u'scream', u'care', u'exactly', u'finally', u'tell', u'mind', u'horror', u'nearly', u'idea', u'strong', u'supposed', u'able', u'wrong', u'couple', u'style', u'obvious', u'shot', u'reason', u'example']\n",
        "[u'person', u'scream', u'worst', u'horror', u'video', u'supposed', u'exactly', u'reason', u'mind', u'boring', u'alien', u'start', u'shot', u'obvious', u'idea', u'entire', u'wrong', u'finally', u'believe', u'try']\n",
        "[u'person', u'scream', u'care', u'exactly', u'finally', u'tell', u'horror', u'mind', u'idea', u'nearly', u'strong', u'supposed', u'wrong', u'able', u'couple', u'shot', u'style', u'example', u'obvious', u'car']\n",
        "[u'person', u'scream', u'horror', u'exactly', u'care', u'mind', u'finally', u'supposed', u'tell', u'idea', u'able', u'wrong', u'nearly', u'shot', u'reason', u'obvious', u'strong', u'boring', u'try', u'entire']\n",
        "[u'person', u'scream', u'care', u'exactly', u'horror', u'mind', u'finally', u'tell', u'supposed', u'idea', u'nearly', u'strong', u'able', u'wrong', u'shot', u'obvious', u'style', u'reason', u'example', u'car']\n",
        "[u'person', u'care', u'scream', u'finally', u'tell', u'exactly', u'strong', u'nearly', u'idea', u'mind', u'wrong', u'couple', u'horror', u'novel', u'supposed', u'able', u'main', u'style', u'live', u'shot']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'person', u'scream', u'care', u'strong', u'finally', u'exactly', u'tell', u'nearly', u'novel', u'mind', u'wrong', u'idea', u'couple', u'horror', u'able', u'supporting', u'style', u'jack', u'supposed', u'live']\n",
        "[u'person', u'care', u'tell', u'finally', u'strong', u'scream', u'couple', u'nearly', u'wrong', u'novel', u'idea', u'exactly', u'mind', u'main', u'able', u'horror', u'supposed', u'live', u'supporting', u'paul']\n",
        "[u'person', u'scream', u'care', u'exactly', u'finally', u'tell', u'horror', u'mind', u'strong', u'idea', u'nearly', u'supposed', u'wrong', u'able', u'couple', u'shot', u'style', u'novel', u'example', u'car']\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}