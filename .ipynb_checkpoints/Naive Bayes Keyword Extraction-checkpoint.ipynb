{
 "metadata": {
  "name": "",
  "signature": "sha256:9a27c919e56e689273adc7776f2b5789e60b221e2849af5c7b58b09f60d109f3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import glob\n",
      "import numpy as np\n",
      "import time\n",
      "from multiprocessing import Pool\n",
      "from anser_indicus.config_settings import DATA_PATH, STAIRCASE_JSON_PATH, QUERY_PATH\n",
      "from anser_indicus.data.database_pool import DatabasePool\n",
      "from anser_indicus.data.queryable_database import QueryableDatabase, KeywordSelection, TimeSelection, Selection, AllSelection\n",
      "from anser_indicus.preprocessing.sparse_matrix import SparseMatrix\n",
      "from anser_indicus.utilities.utc import flexible_htm, htm, mth\n",
      "from anser_indicus.analytics.sparse_low_rank import run_spca\n",
      "\n",
      "def matrix_data_from_keywords(database_name, keywords, time_range):\n",
      "    # Open the database connection\n",
      "    db_pool = DatabasePool()\n",
      "    db = QueryableDatabase(database_name, pool=db_pool)\n",
      "\n",
      "    # Create a selection query from keywords\n",
      "    # One selection specifies the keywords 'OR'ed together\n",
      "    # Another selection specifies all terms excluding the keywords\n",
      "    # Also specify the time range through 'AND'ing them to the selection queries\n",
      "    or_selection, not_selection = Selection(), Selection()\n",
      "    not_selection += TimeSelection(time_range)\n",
      "    or_selection += KeywordSelection(keywords)\n",
      "    or_selection &= TimeSelection(time_range)\n",
      "    db.select(not_selection, classlabel=0, dontclear=False)\n",
      "    db.select(or_selection, classlabel=1, dontclear=True)\n",
      "\n",
      "    # Load and return sparse matrix from iterable, and also classification vector\n",
      "    matrix_data = SparseMatrix()\n",
      "    matrix_data.attach_database(database_name, pool=db_pool)\n",
      "    matrix_data.load_from_iterator(db.iterate_selection())\n",
      "    classification_vector = matrix_data.load_classification_vector(db.iterate_selection_classes())\n",
      "    return matrix_data, classification_vector\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "===== Using AnserIndicus Version 1.1.12 =====\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get matrix data and classification vector for given database and search term\n",
      "\n",
      "database_name = \"aljazeera\"\n",
      "search_term = [\"bomb\"]\n",
      "\n",
      "def to_year(unix_time_stamp):\n",
      "    return int(mth(unix_time_stamp, \"%Y\"))\n",
      "\n",
      "db = QueryableDatabase(database_name)\n",
      "whole_time = tuple(x for x in db.time_range())\n",
      "matrix_data, classification_vector = matrix_data_from_keywords(database_name, search_term, whole_time)\n",
      "print(matrix_data, classification_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "attaching database aljazeera\n",
        "(<anser_indicus.preprocessing.sparse_matrix.SparseMatrix object at 0x134ed8ad0>, array([[ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       ..., \n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.]], dtype=float32))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "\n",
      "N_ITER_PRINT = 100000\n",
      "iteration = 0\n",
      "\n",
      "# Create map of total number of times a given keyword appears in documents\n",
      "positive_appearances = {}\n",
      "negative_appearances = {}\n",
      "positive_counts = 0\n",
      "negative_counts = 0\n",
      "\n",
      "print(\"Counting term frequency...\")\n",
      "\n",
      "# Iterate through sparse matrix\n",
      "cx = scipy.sparse.coo_matrix(matrix_data.mat)\n",
      "length = len(cx.row)\n",
      "\n",
      "for row, col, value in zip(cx.row, cx.col, cx.data):\n",
      "    \n",
      "    # Get the term\n",
      "    term = matrix_data.lookup_terms([col])[0]\n",
      "    \n",
      "    # Initialize dictionary data if not already there\n",
      "    if term not in positive_appearances:\n",
      "        positive_appearances[term] = 0\n",
      "    if term not in negative_appearances:\n",
      "        negative_appearances[term] = 0    \n",
      "    \n",
      "    # Positive class appearance\n",
      "    if classification_vector[row] == 1:\n",
      "        positive_appearances[term] += value\n",
      "    # Negative class appearance\n",
      "    if classification_vector[row] == 0:\n",
      "        negative_appearances[term] += value\n",
      "        \n",
      "    # positive class counts\n",
      "    positive_counts += value\n",
      "    # Negative class counts\n",
      "    negative_counts += value\n",
      "    \n",
      "    if iteration % N_ITER_PRINT == 0:\n",
      "        print(\"Iteration %d of %d\" % (iteration, length))\n",
      "    iteration += 1\n",
      "print(\"Done\")\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counting term frequency...\n",
        "Iteration 0 of 485598"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 100000 of 485598"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 200000 of 485598"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 300000 of 485598"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 400000 of 485598"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute logs of each term, sort by it\n",
      "import math\n",
      "\n",
      "N_SHOW = 20\n",
      "iteration = 0\n",
      "\n",
      "# P(xi | class=1)\n",
      "def P_positive(term):\n",
      "    return (positive_appearances[term]+1) / (positive_counts+1)\n",
      "\n",
      "# P(xi | class = 0)\n",
      "def P_negative(term):\n",
      "    return (negative_appearances[term]+1) / (negative_counts+1)\n",
      "\n",
      "# log ( P(xi | class = 1) / P(xi | class = 0) ) \n",
      "def compute_weight(term):\n",
      "    return math.log(P_positive(term) / P_negative(term))\n",
      "\n",
      "term_weight_pairs = []\n",
      "length = matrix_data.mat.shape[1]\n",
      "for col in range(matrix_data.mat.shape[1]):\n",
      "    \n",
      "    # Compute log-odds\n",
      "    term = matrix_data.lookup_terms([col])[0]\n",
      "    weight = compute_weight(term)\n",
      "    term_weight_pairs.append((term, weight))\n",
      "    \n",
      "    if iteration % N_ITER_PRINT == 0:\n",
      "        print(\"Iteration %d of %d\" % (iteration, length))\n",
      "    iteration += 1\n",
      "    \n",
      "term_weight_pairs.sort(key=lambda x: x[1], reverse=True)\n",
      "print(term_weight_pairs[:N_SHOW])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 0 of 32237\n",
        "[(u'bomb', 6.814542897259958), (u'kovalev', 2.3978952727983707), (u'gujranwala', 2.3978952727983707), (u'abdulmutallab', 2.1972245773362196), (u'tawi', 2.1972245773362196), (u'ayubi', 1.9459101490553132), (u'tianzhu', 1.9459101490553132), (u'kerbala', 1.9459101490553132), (u'peters', 1.9459101490553132), (u'kizilay', 1.9459101490553132), (u'shehu', 1.9459101490553132), (u'samangan', 1.9459101490553132), (u'syrup', 1.9459101490553132), (u'insane', 1.8718021769015913), (u'okah', 1.8718021769015913), (u'underwear', 1.7047480922384253), (u'zalmai', 1.6094379124341003), (u'bukhari', 1.6094379124341003), (u'cirebon', 1.6094379124341003), (u'raman', 1.6094379124341003)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}