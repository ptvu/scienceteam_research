{
 "metadata": {
  "name": "",
  "signature": "sha256:d2aded60d77d62ff419769ab02aa552b0b72219558c8a09a50124387167a3108"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################\n",
      "# Creates a term document matrix from data                        #\n",
      "###################################################################\n",
      "import sys\n",
      "import os\n",
      "import glob\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "START_K = 0\n",
      "K = 1000\n",
      "\n",
      "end_year = 2003\n",
      "start_year = 1992\n",
      "subset_files = 200\n",
      "\n",
      "# get all filenames for year\n",
      "all_file_names = []\n",
      "for yr in range(start_year, end_year + 1):\n",
      "    print \"on file year \" + str(yr)\n",
      "    year_files = glob.glob(str(yr) + \"/*\")\n",
      "    all_file_names += year_files[:subset_files]\n",
      "\n",
      "# Load valid english words\n",
      "valid_words = set()\n",
      "dictionary_file = open(\"words\")\n",
      "for word in dictionary_file:\n",
      "    word = word.lower().strip()\n",
      "    valid_words.add(word)\n",
      "\n",
      "# Load english stop words\n",
      "stop_words = set()\n",
      "stop_words_file = open(\"stop_words\")\n",
      "for word in stop_words_file:\n",
      "    word = word.lower().strip()\n",
      "    stop_words.add(word)\n",
      "print \"finished with stop_words\"\n",
      "\n",
      "# Filter even more. Only take the K top most frequent words from the combined corpus\n",
      "word_frequencies = {}\n",
      "corpus_words = set()\n",
      "for file_name in all_file_names:\n",
      "    f = open(file_name)\n",
      "    text = unicode(f.read(), 'latin-1')\n",
      "    for word in text.split(\" \"):\n",
      "        word = word.lower().strip()\n",
      "        if word in valid_words and word not in stop_words:\n",
      "            if word not in word_frequencies:\n",
      "                word_frequencies[word] = 0\n",
      "            word_frequencies[word] += 1\n",
      "            corpus_words.add(word)\n",
      "    f.close()\n",
      "valid_features = sorted(corpus_words, key=lambda x: word_frequencies[x], reverse=True)[\n",
      "    START_K:START_K + K]\n",
      "print \"filtering done\"\n",
      "\n",
      "# Collect all text\n",
      "corpus = []\n",
      "print \"starting corpus\"\n",
      "for count, file_name in enumerate(all_file_names):\n",
      "    f = open(file_name)\n",
      "    document_string = unicode(f.read(), 'latin-1')\n",
      "    filtered_document_string = \"\"\n",
      "    for word in document_string.split(\" \"):\n",
      "        word = word.lower().strip()\n",
      "        if word in valid_features:\n",
      "            filtered_document_string += word + ' '\n",
      "    corpus.append(filtered_document_string)\n",
      "    f.close()\n",
      "print(\"Done creating corpus!\")\n",
      "\n",
      "# Use Sklearn to get the term document matrix\n",
      "vectorizer = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
      "term_doc_matrix = vectorizer.fit_transform(corpus)\n",
      "\n",
      "# tdm and features\n",
      "tdm = term_doc_matrix.toarray()\n",
      "features = vectorizer.get_feature_names()\n",
      "\n",
      "print(\"Number of rows: %d cols: %d\" % tdm.shape)\n",
      "print(tdm)\n",
      "print(\"Features:\")\n",
      "print(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "on file year 1992\n",
        "on file year 1993\n",
        "on file year 1994\n",
        "on file year 1995\n",
        "on file year 1996\n",
        "on file year 1997\n",
        "on file year 1998"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "on file year 1999\n",
        "on file year 2000\n",
        "on file year 2001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "on file year 2002\n",
        "on file year 2003\n",
        "finished with stop_words"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "filtering done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "starting corpus\n",
        "Done creating corpus!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of rows: 2400 cols: 972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.          0.0118525   0.         ...,  0.03260386  0.0145315\n",
        "   0.03058228]\n",
        " [ 0.          0.          0.         ...,  0.          0.05508692  0.        ]\n",
        " [ 0.          0.01602831  0.         ...,  0.033068    0.          0.04824966]\n",
        " ..., \n",
        " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " [ 0.0204916   0.          0.02034914 ...,  0.04559966  0.01161355\n",
        "   0.02444131]\n",
        " [ 0.          0.          0.         ...,  0.          0.          0.02080194]]\n",
        "Features:\n",
        "[u'abelian', u'able', u'absence', u'according', u'account', u'act', u'acting', u'action', u'acts', u'actual', u'actually', u'add', u'added', u'addition', u'additional', u'address', u'adjoint', u'admit', u'affine', u'agreement', u'aim', u'algebra', u'algebraic', u'allow', u'alternative', u'amplitude', u'analogous', u'analogue', u'analogy', u'analysis', u'analytic', u'analyze', u'angle', u'angular', u'annihilation', u'anomalous', u'anomaly', u'answer', u'appear', u'appearance', u'appendix', u'application', u'applied', u'apply', u'approach', u'appropriate', u'approximation', u'arbitrary', u'argue', u'argument', u'arise', u'arrive', u'associated', u'assume', u'assumed', u'assuming', u'assumption', u'asymptotic', u'asymptotically', u'attention', u'automatically', u'auxiliary', u'average', u'avoid', u'axial', u'axion', u'background', u'bare', u'base', u'based', u'basic', u'basis', u'begin', u'behavior', u'belong', u'bianchi', u'bilinear', u'black', u'bound', u'boundary', u'bounded', u'bracket', u'branch', u'break', u'breaking', u'briefly', u'broken', u'built', u'bulk', u'bundle', u'calculate', u'calculated', u'calculating', u'calculation', u'calculus', u'cancel', u'cancellation', u'canonical', u'carried', u'carry', u'casimir', u'center', u'central', u'chain', u'change', u'chapter', u'character', u'characteristic', u'charge', u'check', u'checked', u'chiral', u'choice', u'choose', u'choosing', u'chosen', u'circle', u'class', u'classes', u'classical', u'classification', u'clifford', u'close', u'closed', u'closely', u'coefficient', u'coincide', u'collective', u'color', u'combination', u'combined', u'comes', u'coming', u'comment', u'common', u'commutation', u'commutative', u'commutator', u'commute', u'commuting', u'compact', u'compare', u'comparison', u'compatible', u'complete', u'completely', u'complex', u'complicated', u'component', u'composite', u'computation', u'compute', u'concerning', u'conclude', u'conclusion', u'condensation', u'condition', u'cone', u'configuration', u'confinement', u'conformal', u'conjecture', u'conjugate', u'conjugation', u'connected', u'connection', u'consequence', u'conservation', u'consider', u'consideration', u'considered', u'considering', u'consistency', u'consistent', u'constant', u'constrained', u'constraint', u'construct', u'construction', u'contact', u'contain', u'content', u'context', u'continuation', u'continuous', u'continuum', u'contour', u'contrast', u'contribute', u'contribution', u'convenient', u'conventional', u'correct', u'correction', u'correlation', u'correspond', u'correspondence', u'corresponding', u'coset', u'cosmic', u'cosmological', u'coulomb', u'counting', u'couple', u'coupled', u'coupling', u'course', u'covariant', u'covering', u'creation', u'critical', u'cross', u'crucial', u'cubic', u'current', u'curvature', u'curve', u'curved', u'cut', u'cutoff', u'data', u'deal', u'decay', u'decomposition', u'define', u'defined', u'definite', u'definition', u'deformation', u'deformed', u'degeneracy', u'degenerate', u'degree', u'demonstrate', u'denote', u'density', u'department', u'depend', u'dependence', u'dependent', u'depending', u'derivation', u'derivative', u'derive', u'derived', u'description', u'desired', u'detailed', u'determinant', u'determine', u'determined', u'di', u'diagonal', u'diagram', u'difference', u'differential', u'difficult', u'dimension', u'dimensional', u'direct', u'direction', u'directly', u'discrete', u'discuss', u'discussion', u'distance', u'distinct', u'distribution', u'divergence', u'divergent', u'domain', u'double', u'dual', u'duality', u'dynamical', u'dynamics', u'easily', u'easy', u'edge', u'effect', u'effective', u'effectively', u'effects', u'eigenvalue', u'electric', u'electromagnetic', u'element', u'elementary', u'eliminate', u'elliptic', u'energy', u'ensure', u'entire', u'entropy', u'equal', u'equality', u'equation', u'equivalence', u'equivalent', u'especially', u'essential', u'essentially', u'establish', u'established', u'euclidean', u'evaluate', u'evaluation', u'event', u'evidence', u'evolution', u'exact', u'exactly', u'examine', u'example', u'exceptional', u'exchange', u'exist', u'existence', u'expand', u'expanded', u'expanding', u'expansion', u'expect', u'expectation', u'explain', u'explicit', u'explicitly', u'exponent', u'exponential', u'exponentially', u'express', u'expressed', u'expression', u'extend', u'extended', u'extension', u'exterior', u'external', u'extra', u'extract', u'extreme', u'factor', u'familiar', u'family', u'feature', u'fiber', u'field', u'figure', u'file', u'final', u'finally', u'finding', u'finite', u'fix', u'fixed', u'fixing', u'flat', u'flow', u'flux', u'focus', u'follow', u'following', u'force', u'form', u'formal', u'formalism', u'formally', u'formula', u'formulae', u'formulation', u'fractional', u'frame', u'framework', u'free', u'freedom', u'frequency', u'function', u'functional', u'fundamental', u'fusion', u'future', u'gas', u'gauge', u'gaussian', u'generalization', u'generalize', u'generalized', u'generate', u'generating', u'generator', u'generic', u'genus', u'geodesic', u'geometric', u'geometrical', u'geometry', u'ghost', u'giving', u'global', u'goes', u'grant', u'graph', u'grateful', u'gravitational', u'gravity', u'green', u'ground', u'half', u'hall', u'hamiltonian', u'hand', u'hard', u'harmonic', u'hawking', u'heat', u'height', u'help', u'heterotic', u'hidden', u'hierarchy', u'hold', u'hole', u'holomorphic', u'homogeneous', u'hope', u'horizon', u'hyperbolic', u'idea', u'identical', u'identification', u'identify', u'identity', u'illustrate', u'image', u'imaginary', u'immediately', u'imply', u'impose', u'imposing', u'include', u'included', u'independent', u'index', u'indicate', u'indices', u'induced', u'infinite', u'infinitely', u'infinitesimal', u'infinity', u'information', u'infrared', u'initial', u'inner', u'insertion', u'inside', u'instance', u'instead', u'institute', u'integer', u'integrable', u'integral', u'integrand', u'integrate', u'integration', u'interaction', u'intermediate', u'internal', u'interpret', u'interpretation', u'intersection', u'interval', u'introduce', u'introduction', u'invariance', u'invariant', u'inverse', u'investigate', u'involve', u'involved', u'irreducible', u'irrelevant', u'isometry', u'isomorphic', u'isomorphism', u'issue', u'jan', u'keeping', u'kernel', u'key', u'killing', u'kinetic', u'kink', u'label', u'lagrangian', u'landau', u'language', u'latex', u'lattice', u'law', u'lax', u'lead', u'leading', u'leads', u'leave', u'leaves', u'led', u'left', u'lemma', u'length', u'level', u'lie', u'light', u'limit', u'line', u'linear', u'linearly', u'link', u'list', u'literature', u'little', u'local', u'locally', u'logarithmic', u'longitudinal', u'look', u'looking', u'loop', u'loss', u'low', u'lower', u'magnetic', u'main', u'manifest', u'manifestly', u'manifold', u'manner', u'map', u'marginal', u'mass', u'massive', u'massless', u'master', u'matching', u'mathematical', u'matrices', u'matrix', u'matter', u'maximal', u'maximum', u'maxwell', u'mean', u'meaning', u'measure', u'mechanical', u'mechanics', u'mechanism', u'membrane', u'mention', u'method', u'metric', u'metrics', u'microscopic', u'minimal', u'minimum', u'minus', u'mirror', u'mode', u'model', u'modification', u'modular', u'module', u'modulo', u'moment', u'momenta', u'momentum', u'monodromy', u'monopole', u'motion', u'moving', u'multiple', u'multiplet', u'multiplication', u'natural', u'naturally', u'nature', u'necessarily', u'negative', u'noncommutative', u'nonlinear', u'nonlocal', u'nonzero', u'norm', u'normal', u'normalization', u'notation', u'note', u'noted', u'notice', u'notion', u'null', u'numerical', u'obey', u'object', u'observable', u'observation', u'observe', u'obtain', u'obvious', u'obviously', u'occur', u'odd', u'operator', u'opposite', u'orbit', u'ordinary', u'origin', u'original', u'orthogonal', u'oscillator', u'outside', u'overall', u'page', u'pair', u'paper', u'parallel', u'parameter', u'parity', u'partial', u'particle', u'particular', u'particularly', u'partition', u'path', u'perform', u'period', u'periodic', u'perturbation', u'perturbative', u'phase', u'phases', u'phenomenon', u'photon', u'physical', u'physically', u'physics', u'picture', u'piece', u'planar', u'plane', u'play', u'plus', u'polarization', u'pole', u'polynomial', u'position', u'positive', u'possibility', u'potential', u'power', u'precise', u'precisely', u'preprint', u'prescription', u'presence', u'preserve', u'previous', u'previously', u'primary', u'principal', u'principle', u'probability', u'procedure', u'proceed', u'process', u'produce', u'product', u'projection', u'projective', u'proof', u'propagator', u'proper', u'property', u'proportional', u'prove', u'proved', u'provide', u'provided', u'pure', u'purely', u'purpose', u'quadratic', u'quantity', u'quantization', u'quantum', u'quark', u'question', u'quotient', u'radial', u'radiation', u'radius', u'random', u'range', u'rank', u'ratio', u'rational', u'read', u'reader', u'real', u'realization', u'reason', u'recall', u'recent', u'recently', u'recover', u'recursion', u'reduce', u'reduced', u'reduction', u'refer', u'reference', u'reflection', u'regime', u'region', u'regular', u'regularization', u'relate', u'related', u'relation', u'relative', u'relativistic', u'relativity', u'relevant', u'remain', u'remains', u'remark', u'remarkable', u'replace', u'represent', u'representation', u'reproduce', u'require', u'requirement', u'research', u'residual', u'resolution', u'respect', u'respectively', u'rest', u'restrict', u'restricted', u'restriction', u'result', u'resulting', u'return', u'review', u'rewrite', u'riemannian', u'ring', u'rise', u'role', u'root', u'rotation', u'rule', u'running', u'satisfied', u'satisfy', u'satisfying', u'scalar', u'scale', u'scaled', u'scales', u'scaling', u'scattering', u'scheme', u'section', u'sector', u'seen', u'semiclassical', u'sense', u'separate', u'separation', u'sequence', u'series', u'set', u'setting', u'sheet', u'shell', u'shift', u'short', u'shown', u'sigma', u'sign', u'signature', u'similar', u'similarly', u'simple', u'simpler', u'simplicity', u'simplify', u'simply', u'single', u'singular', u'singularity', u'sitter', u'situation', u'size', u'slightly', u'smooth', u'solution', u'solvable', u'solve', u'somewhat', u'source', u'space', u'spatial', u'special', u'specific', u'specify', u'spectral', u'spectrum', u'sphere', u'spherical', u'spin', u'split', u'square', u'stability', u'stable', u'standard', u'star', u'start', u'starting', u'statement', u'static', u'stationary', u'statistical', u'statistics', u'step', u'straightforward', u'strength', u'stress', u'strictly', u'string', u'stringy', u'strong', u'strongly', u'structure', u'studied', u'study', u'subalgebra', u'subgroup', u'subject', u'subsection', u'subset', u'subspace', u'substituting', u'sufficient', u'sufficiently', u'suggest', u'suitable', u'sum', u'summation', u'super', u'support', u'suppose', u'surface', u'symbol', u'symmetric', u'symmetry', u'symplectic', u'table', u'taking', u'tangent', u'target', u'technical', u'technique', u'temperature', u'tension', u'tensor', u'term', u'test', u'text', u'thank', u'theorem', u'theoretical', u'theory', u'thermal', u'thermodynamic', u'time', u'times', u'toda', u'topological', u'topology', u'torsion', u'torus', u'total', u'trace', u'transfer', u'transform', u'transformation', u'transition', u'translation', u'transverse', u'treat', u'treatment', u'tree', u'trivial', u'true', u'try', u'twist', u'twisted', u'type', u'typical', u'ultraviolet', u'unbroken', u'underlying', u'understand', u'understanding', u'understood', u'unique', u'uniquely', u'unit', u'unitary', u'universal', u'universe', u'university', u'unless', u'unlike', u'unstable', u'untwisted', u'upper', u'useful', u'usual', u'usually', u'vacuum', u'valid', u'value', u'valued', u'van', u'vanish', u'vanishing', u'variable', u'variation', u'various', u'vector', u'velocity', u'verify', u'version', u'vertex', u'vertical', u'vertices', u'view', u'volume', u'vortex', u'vortices', u'wall', u'ward', u'wave', u'weak', u'weight', u'width', u'wilson', u'winding', u'wish', u'world', u'worth', u'wrapped', u'write', u'writing', u'written', u'yield', u'zero']\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright (c) 2014 Steve Yadlowsky, Preetum Nakkarin.\n",
      "# Licensed under MIT License.\n",
      "# More information including the exact terms of the License\n",
      "# can be found in the file COPYING in the project root directory.\n",
      "import numpy as np\n",
      "import time\n",
      "import operator\n",
      "import scipy.sparse\n",
      "\n",
      "\n",
      "class IHTClassifier(object):\n",
      "\n",
      "    def __init__(self):\n",
      "        self.training_time = 0.0\n",
      "        self.beta = None\n",
      "\n",
      "    def card(self, x):\n",
      "        return np.sum(x != 0)\n",
      "\n",
      "    def train(self, X, y, card=100, verbose=False):\n",
      "        start = time.time()\n",
      "        if verbose:\n",
      "            print \"Preconditioning matrix\"\n",
      "        whitened_X, feature_avg = self.whiten_features(X)\n",
      "        lsv = float(self.compute_lsv(whitened_X, feature_avg))\n",
      "        if verbose:\n",
      "            print \"Matching pursuits\"\n",
      "        x_hat = self.matching_pursuit_sparse(y, whitened_X / lsv, feature_avg / lsv, card)\n",
      "        if verbose:\n",
      "            print \"Running iterative hard thresholding\"\n",
      "        self.beta = self.AIHT_sparse(y, whitened_X / lsv, x_hat, card, feature_avg / lsv) / lsv\n",
      "\n",
      "        self.training_time += time.time() - start\n",
      "\n",
      "    def whiten_features(self, X):\n",
      "        X = X.tocsr(copy=True)\n",
      "        row_avg = np.bincount(X.indices, weights=X.data)\n",
      "        row_avg /= float(X.shape[0])\n",
      "        row_norm = np.bincount(X.indices, weights=(X.data - row_avg[X.indices]) ** 2)\n",
      "        nonzeros_in_each_column = np.diff(X.tocsc().indptr)\n",
      "        avg_norm = ((float(X.shape[0]) * np.ones(X.shape[1])) -\n",
      "                    nonzeros_in_each_column) * (row_avg ** 2)\n",
      "        row_norm += avg_norm\n",
      "        row_norm = np.array([np.sqrt(x) if x != 0 else 1 for x in row_norm])\n",
      "        row_avg /= row_norm\n",
      "        X.data /= np.take(row_norm, X.indices)\n",
      "        feature_avg = np.squeeze(row_avg)\n",
      "\n",
      "        return X, feature_avg\n",
      "\n",
      "    def compute_lsv(self, X, feature_avg):\n",
      "        def matmuldyad(v):\n",
      "            return X.dot(v) - feature_avg.dot(v)\n",
      "\n",
      "        def rmatmuldyad(v):\n",
      "            return X.T.dot(v) - v.sum() * feature_avg\n",
      "        normalized_lin_op = scipy.sparse.linalg.LinearOperator(X.shape, matmuldyad, rmatmuldyad)\n",
      "\n",
      "        def matvec_XH_X(v):\n",
      "            return normalized_lin_op.rmatvec(normalized_lin_op.matvec(v))\n",
      "\n",
      "        which = 'LM'\n",
      "        v0 = None\n",
      "        maxiter = None\n",
      "        return_singular_vectors = False\n",
      "\n",
      "        XH_X = scipy.sparse.linalg.LinearOperator(\n",
      "            matvec=matvec_XH_X, dtype=X.dtype, shape=(X.shape[1], X.shape[1]))\n",
      "        eigvals = scipy.sparse.linalg.eigs(\n",
      "            XH_X, k=1, tol=0, maxiter=None, ncv=10, which=which, v0=v0, return_eigenvectors=False)\n",
      "        lsv = np.sqrt(eigvals)\n",
      "        return lsv[0].real\n",
      "\n",
      "    def matching_pursuit_sparse(self, y, X, feature_avg, k, tol=10 ** -10):\n",
      "        '''\n",
      "        Matching Pursuit\n",
      "        '''\n",
      "        r = y\n",
      "        X = X.tocsc()\n",
      "        err_norm = np.linalg.norm(r, 2)\n",
      "        err_norm_prev = 0\n",
      "        beta = np.zeros(X.shape[1])\n",
      "        while self.card(beta) < k:\n",
      "            all_inner_products = X.T.dot(r) - np.sum(r) * feature_avg\n",
      "            max_index, max_abs_inner_product = max(\n",
      "                enumerate(np.abs(all_inner_products)), key=operator.itemgetter(1))\n",
      "            g = X[:, max_index]\n",
      "            g = np.squeeze(np.asarray(g.todense())) - feature_avg[max_index]\n",
      "            a = all_inner_products[max_index]\n",
      "            a /= np.linalg.norm(g, 2) ** 2\n",
      "            beta[max_index] += a\n",
      "            r = r - a * g\n",
      "            err_norm_prev = err_norm\n",
      "            err_norm = np.linalg.norm(r, 2)\n",
      "            if np.abs(err_norm - err_norm_prev) <= tol:\n",
      "                break\n",
      "        return beta\n",
      "\n",
      "    def thresholder(self, y, m):\n",
      "        sort_y = sorted(np.abs(y))\n",
      "        thresh = sort_y[-m]\n",
      "\n",
      "        non_thresholded_indices = (np.abs(y) > thresh)\n",
      "        n_nonzero_indices = sum(non_thresholded_indices)\n",
      "        if n_nonzero_indices < m:\n",
      "            collisions = np.where((np.abs(y) == thresh))[0]\n",
      "            passed = np.random.choice(collisions, m - n_nonzero_indices)\n",
      "            non_thresholded_indices[passed] = 1\n",
      "\n",
      "        y_new = non_thresholded_indices * y\n",
      "\n",
      "        return y_new, thresh\n",
      "\n",
      "    def AIHT_sparse(self, y, X, beta, k, feature_avg=None, alpha=0, example_weights=None, max_iters=10000, tol=10 ** -16):\n",
      "        \"\"\"Solves DORE accelerated IHT with a sparse matrix X.\n",
      "        \"\"\"\n",
      "        m, n = X.shape\n",
      "        y = np.squeeze(np.asarray(y))\n",
      "        err_norm_prev = 0\n",
      "        beta_0 = beta\n",
      "        beta_prev = beta\n",
      "        X_beta = 0\n",
      "        X_beta_prev = 0\n",
      "        X_beta_twice_prev = 0\n",
      "\n",
      "        if feature_avg is None:\n",
      "            feature_avg = np.zeros(n)\n",
      "\n",
      "        if example_weights is None:\n",
      "            example_weights = np.ones(m)\n",
      "\n",
      "        for iter_ in xrange(max_iters):\n",
      "            X_beta_twice_prev = X_beta_prev\n",
      "            X_beta_prev = X_beta\n",
      "            X_beta = (X.dot(beta) - feature_avg.dot(beta))\n",
      "            X_beta = np.squeeze(np.asarray(X_beta))\n",
      "            err = y - example_weights * X_beta\n",
      "            err_reg = -alpha * beta\n",
      "            norm_change = ((np.linalg.norm(beta - beta_prev) ** 2) / n)\n",
      "            print err.dot(err) + err_reg.dot(err_reg), norm_change, np.linalg.norm(beta)\n",
      "\n",
      "            if iter_ > 0 and (norm_change <= tol):\n",
      "                break\n",
      "\n",
      "            beta_t = beta + np.squeeze(np.asarray(X.T.dot(err))) - \\\n",
      "                err.sum() * feature_avg + alpha * err_reg\n",
      "            beta_t = np.squeeze(np.asarray(beta_t))\n",
      "\n",
      "            beta_t, thresh = self.thresholder(beta_t, k)\n",
      "            X_beta = X.dot(beta_t) - feature_avg.dot(beta_t)\n",
      "            X_beta = np.squeeze(X_beta)\n",
      "            err = y - example_weights * X_beta\n",
      "            err_reg = -alpha * beta_t\n",
      "\n",
      "            beta_t_star = beta_t\n",
      "            if iter_ > 2:\n",
      "                delta_X_beta = X_beta - X_beta_prev\n",
      "                delta_regularization = alpha * (beta_t - beta)\n",
      "                dp = delta_X_beta.dot(example_weights * delta_X_beta) + \\\n",
      "                    delta_regularization.dot(delta_regularization)\n",
      "                if dp > 0:\n",
      "                    a1 = (delta_X_beta.dot(err) + delta_regularization.dot(err_reg)) / dp\n",
      "                    X_beta_1 = (1 + a1) * X_beta - a1 * X_beta_prev\n",
      "                    beta_1 = beta_t + a1 * (beta_t - beta)\n",
      "                    err_1 = y - example_weights * X_beta_1\n",
      "                    err_1_reg = -alpha * beta_1\n",
      "\n",
      "                    delta_X_beta = X_beta_1 - X_beta_twice_prev\n",
      "                    delta_regularization = alpha * (beta_1 - beta_prev)\n",
      "                    dp = delta_X_beta.dot(example_weights * delta_X_beta) + \\\n",
      "                        delta_regularization.dot(delta_regularization)\n",
      "                    if dp > 0:\n",
      "                        a2 = (delta_X_beta.dot(err_1) + delta_regularization.dot(err_1_reg)) / dp\n",
      "                        beta_2 = beta_1 + a2 * (beta_1 - beta_prev)\n",
      "                        beta_2, thresh = self.thresholder(beta_2, k)\n",
      "\n",
      "                        X_beta_2 = X.dot(beta_2) - feature_avg.dot(beta_2)\n",
      "                        X_beta_2 = np.squeeze(np.asarray(X_beta_2))\n",
      "                        err_2 = y - example_weights * X_beta_2\n",
      "                        err_reg_2 = -alpha * beta_2\n",
      "\n",
      "                        if (err_2.dot(err_2) + err_reg_2.dot(err_reg_2)) / (err.dot(err) + err_reg.dot(err_reg)) < 1:\n",
      "                            beta_t_star = beta_2\n",
      "                            X_beta = X_beta_2\n",
      "\n",
      "            beta_prev = beta\n",
      "            beta = beta_t_star\n",
      "\n",
      "        return beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query = unicode('vector')\n",
      "query_in_features = False\n",
      "\n",
      "if query in features:\n",
      "        location_in_matrix = features.index(query)\n",
      "        features.remove(query)\n",
      "\n",
      "        # Remove column with query term from tdm\n",
      "        tdm = np.delete(tdm, location_in_matrix, axis=1)\n",
      "        query_in_features = True\n",
      "        A=tdm\n",
      "\n",
      "for year in range(1992, 2004):\n",
      "    print \"For year \" + str(year)\n",
      "    ###################################################################\n",
      "    # Searches query term within list of corpus                       #\n",
      "    ###################################################################\n",
      "\n",
      "    query_presence_indicators = []\n",
      "    \n",
      "    # Create the indicator column\n",
      "    if query_in_features:\n",
      "        # Construct indicator vector\n",
      "        for i in range((year-1992)*subset_files):\n",
      "            query_presence_indicators.append(-1)\n",
      "        for i in range((year-1992)*subset_files, (year-1992+1)*subset_files):\n",
      "            query_presence_indicators.append(1)\n",
      "        for i in range((year-1992+1)*subset_files, len(tdm)):\n",
      "            query_presence_indicators.append(-1)    \n",
      "    else:\n",
      "        print(\"Query not found\")\n",
      "\n",
      "    print(\"Number of documents\", len(query_presence_indicators))\n",
      "    print(\"Number of times query appears in all documents: \", sum(\n",
      "        [1 if x == 1 else 0 for x in query_presence_indicators]))\n",
      "\n",
      "\n",
      "    b = query_presence_indicators\n",
      "    classifier = IHTClassifier()\n",
      "    sparse_matrix = scipy.sparse.csr_matrix(A)\n",
      "    classifier.train(sparse_matrix, b, verbose=True)\n",
      "    IHT_weights = classifier.beta\n",
      "\n",
      "    ####################################################################################\n",
      "    # Sorts words by their weights of the above computed portion                       #\n",
      "    ####################################################################################\n",
      "\n",
      "    print(\"IHT Keywords\")\n",
      "    all_terms = [(x, IHT_weights[i]) for i, x in enumerate(features)]\n",
      "    all_terms.sort(key=lambda x: x[1], reverse=True)\n",
      "    print([x[0] for x in all_terms[:20]])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For year 1992\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2161.56986139 0.0 58.1635058414\n",
        "2161.08061973 0.000259467791454 58.1335384011\n",
        "2160.64590068 0.000230370500956 58.1145730583\n",
        "2160.25841984 0.000205188137034 58.1050780771\n",
        "2156.95496202 0.0630651694719 58.5765020616\n",
        "2156.51644246"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00669331657358 59.6798695077\n",
        "2156.48089756 0.000467100298595 59.8388836255\n",
        "2156.47572389 6.66247710545e-05 59.8941268854\n",
        "2156.47476467"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.42828478373e-05 59.8883848016\n",
        "2156.47467106 1.13832531771e-06 59.887362058\n",
        "2156.47465682"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.96367868094e-07 59.886568214\n",
        "2156.47465532 2.2950071557e-08 59.886626303\n",
        "2156.47465514 2.73134869651e-09 59.8865939714\n",
        "2156.47465512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.0445944972e-10 59.8865605655\n",
        "2156.47465512 4.8834125897e-11 59.8865697494\n",
        "2156.47465512 2.94018597944e-12 59.8865741326\n",
        "2156.47465512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.46777142017e-13 59.8865748156\n",
        "2156.47465512 8.55476502459e-17 59.8865747906\n",
        "IHT Keywords\n",
        "[u'preprint', u'scaled', u'ward', u'current', u'ring', u'critical', u'measure', u'primary', u'hole', u'di', u'proof', u'discrete', u'polynomial', u'classical', u'riemannian', u'modular', u'central', u'transform', u'family', u'ground']\n",
        "For year 1993\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2203.16050828 0.0 53.0952215907\n",
        "2202.79951297 0.000191874718748 53.1433127072\n",
        "2202.48148557 0.000168861989984 53.1975396941\n",
        "2202.20017961 0.000149226891031 53.2565985242\n",
        "2199.94639424 0.0406402539387 54.6876142344\n",
        "2199.67080541"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00351411760097 55.6698270463\n",
        "2199.63129554 0.000529394347086 55.9128670688\n",
        "2199.62586426 7.75861927313e-05 55.9237209974\n",
        "2199.62495685 1.42014389863e-05 55.9156814179\n",
        "2199.62486169 1.31199543358e-06 55.9147894159\n",
        "2199.62485165"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.50335998295e-07 55.9144603477\n",
        "2199.62485058 1.62380375355e-08 55.9149937826\n",
        "2199.62485044 2.39979087834e-09 55.915011602\n",
        "2199.62485043 1.39884925961e-10 55.9150009473\n",
        "2199.62485043"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.17763495231e-11 55.9149973692\n",
        "2199.62485043 1.53263509901e-12 55.9149986155\n",
        "2199.62485043 1.49910677101e-13 55.9149962187\n",
        "2199.62485043"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.03672666911e-16 55.914996236\n",
        "2199.62485043 1.71252025211e-14 55.9149964306\n",
        "2199.62485043 4.41180591162e-17 55.9149964024\n",
        "IHT Keywords\n",
        "[u'jan', u'preprint', u'commute', u'fusion', u'technical', u'topological', u'loop', u'super', u'solvable', u'hawking', u'double', u'specify', u'distinct', u'specific', u'derive', u'moment', u'equivalent', u'notion', u'vertices', u'physically']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "For year 1994\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2186.04099372 0.0 57.5363572084\n",
        "2185.63579123 0.000214713059488 57.60681742\n",
        "2185.27452825"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.000191295991765 57.6792139406\n",
        "2184.95156573 0.000170909586672 57.7529865596\n",
        "2182.13813805 0.0547882255556 59.5740357142\n",
        "2181.88204103"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00321109592618 60.2135131476\n",
        "2181.83560484 0.00059057891784 60.5347529889\n",
        "2181.82915409 8.90532879965e-05 60.5609239919\n",
        "2181.82837194"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.09807499411e-05 60.5426662846\n",
        "2181.82828282 1.15478202767e-06 60.5379158236\n",
        "2181.82827206"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.54329040943e-07 60.5377180298\n",
        "2181.82827071 2.06820629147e-08 60.5378782584\n",
        "2181.82827058"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.21426106525e-09 60.5378378845\n",
        "2181.82827056 2.43607207002e-10 60.5378887765\n",
        "2181.82827056 1.96139788506e-11 60.5378893902\n",
        "2181.82827056 9.97897593233e-13 60.5378868274\n",
        "2181.82827056"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.18941726585e-13 60.5378869354\n",
        "2181.82827056 1.65371057094e-16 60.5378869144\n",
        "2181.82827056"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.04857141342e-14 60.5378866397\n",
        "2181.82827056 1.0034050516e-15 60.537886695\n",
        "2181.82827056 2.62041381347e-17 60.5378866987\n",
        "IHT Keywords"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'jan', u'calculus', u'sum', u'quantum', u'broken', u'physical', u'transformation', u'weight', u'matrix', u'landau', u'element', u'object', u'locally', u'statistics', u'obvious', u'statement', u'polynomial', u'principal', u'essential', u'cross']\n",
        "For year 1995\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2200.34697195 0.0 55.5795500496\n",
        "2199.83185804 0.000273779386255 55.755992903\n",
        "2199.37793427 0.000240997455507 55.9314778074\n",
        "2198.97624632 0.000213060046213 56.1051048047\n",
        "2195.7388647"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.058694031965 59.4998851726\n",
        "2195.32529476 0.00531231907955 60.7108383581\n",
        "2195.26949784 0.000778821895475 60.9683681829\n",
        "2195.26354263 7.7184632028e-05 60.9746134927\n",
        "2195.26248708 1.6605010202e-05 60.9668442139\n",
        "2195.26237779"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.68499402137e-06 60.9618141271\n",
        "2195.26236876 1.31058610003e-07 60.9595611534\n",
        "2195.26236759 1.59903755591e-08 60.9591675083\n",
        "2195.26236745 2.11963813895e-09 60.9592006254\n",
        "2195.26236744 2.06440262374e-10 60.9592010554\n",
        "2195.26236744"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.13307721959e-11 60.9592092621\n",
        "2195.26236744 2.7063906125e-12 60.9592162126\n",
        "2195.26236744 2.56955892529e-13 60.9592151073\n",
        "2195.26236744 7.32044549743e-17 60.9592151406\n",
        "IHT Keywords\n",
        "[u'jan', u'auxiliary', u'functional', u'lattice', u'sequence', u'transfer', u'periodic', u'opposite', u'bianchi', u'green', u'world', u'affine', u'minimum', u'add', u'charge', u'understanding', u'graph', u'scalar', u'absence', u'solution']\n",
        "For year 1996\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2241.43556462 0.0 49.5313275996\n",
        "2241.05619038 0.000201011517252 49.6627727639\n",
        "2240.71799493 0.000179104821897 49.7926709\n",
        "2240.41592338 0.000159901993124 49.9205567963\n",
        "2237.82852111 0.0496088941945 52.6432542365\n",
        "2237.62238107"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00285845209857 53.2973047578\n",
        "2237.59508248 0.000304476965376 53.403818179\n",
        "2237.59205967 4.84892809566e-05 53.3897587939\n",
        "2237.59177582 4.26285518073e-06 53.3795088994\n",
        "2237.59173726 6.09040478982e-07 53.3774492381\n",
        "2237.5917351 3.43170628509e-08 53.3778390618\n",
        "2237.59173496"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.91868245511e-09 53.3781063462\n",
        "2237.59173495 1.93786533532e-10 53.3781881445\n",
        "2237.59173495 2.46172521844e-11 53.3781741082\n",
        "2237.59173495 1.79408762637e-12 53.3781705849\n",
        "2237.59173495 8.61125656819e-14 53.3781709152\n",
        "2237.59173495"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.87671771485e-15 53.3781710493\n",
        "2237.59173495 5.59393296121e-17 53.378171067\n",
        "IHT Keywords\n",
        "[u'duality', u'bilinear', u'heat', u'scheme', u'monopole', u'page', u'statistical', u'coming', u'electromagnetic', u'identity', u'calculus', u'particle', u'examine', u'fixed', u'led', u'previously', u'massless', u'proportional', u'product', u'reflection']\n",
        "For year 1997\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2250.35888652 0.0 48.1174431053\n",
        "2249.80807915 0.000291997148882 48.2320283284\n",
        "2249.31719961 0.000259870065693 48.3514719462\n",
        "2248.8774735 0.000232528291916 48.4743712429\n",
        "2244.8729224 0.0812511778033 51.6169161366\n",
        "2244.41476765 0.00484779876707 52.7052844474\n",
        "2244.32092497 0.00145513194097 53.2391266748\n",
        "2244.31369669"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.000106359743794 53.261614672\n",
        "2244.31299674 9.73897261013e-06 53.2465376164\n",
        "2244.3129018 1.35097269842e-06 53.2412925929\n",
        "2244.31289383 1.17849544651e-07 53.2401335404\n",
        "2244.3128931 1.05350685619e-08 53.2404854904\n",
        "2244.31289304 8.45953663961e-10 53.2404638682\n",
        "2244.31289303"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.06726344626e-11 53.2404611996\n",
        "2244.31289303 2.75493598081e-11 53.2404489574\n",
        "2244.31289303 3.1363557452e-12 53.2404462034\n",
        "2244.31289303 2.51496690661e-13 53.2404448557\n",
        "2244.31289303"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.84745401651e-14 53.2404448601\n",
        "2244.31289303 6.16648659891e-18 53.2404448668\n",
        "IHT Keywords\n",
        "[u'manifest', u'fiber', u'spectral', u'recent', u'electric', u'strongly', u'elliptic', u'write', u'solvable', u'content', u'strength', u'singular', u'choice', u'coupling', u'diagram', u'axion', u'subset', u'branch', u'role', u'algebra']\n",
        "For year 1998\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2220.32870474 0.0 52.7249801911\n",
        "2219.84231688 0.000257875203504 52.8246774364\n",
        "2219.40972038 0.000229210026608 52.9272226072\n",
        "2219.02399759 0.000204254762758 53.0316524792\n",
        "2215.75045409 0.0622330328184 55.465212875\n",
        "2215.41907238 0.00469085379511 56.4746552391\n",
        "2215.37892568"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.000572281415051 56.6838054905\n",
        "2215.3752943 5.23455127235e-05 56.6754029515\n",
        "2215.37467061 8.94438953997e-06 56.6616941385\n",
        "2215.37457998 1.31261061461e-06 56.6542951239\n",
        "2215.37456843 1.75762781785e-07 56.6556615905\n",
        "2215.37456656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.67328053605e-08 56.65607321\n",
        "2215.37456628 4.03607152412e-09 56.656168464\n",
        "2215.37456625 4.0548833711e-10 56.6561558985\n",
        "2215.37456625 4.34431582986e-11 56.6561417885\n",
        "2215.37456625 4.18779987722e-12 56.6561379113\n",
        "2215.37456625"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.3753810463e-13 56.6561373962\n",
        "2215.37456625 3.41489069838e-14 56.6561372654\n",
        "2215.37456625 2.31490253193e-15 56.6561372256\n",
        "2215.37456625 4.10611485365e-18 56.6561372234\n",
        "IHT Keywords\n",
        "[u'text', u'anomaly', u'microscopic', u'gas', u'breaking', u'maximal', u'coulomb', u'circle', u'matrix', u'various', u'direction', u'multiplet', u'interaction', u'static', u'observe', u'study', u'correct', u'evidence', u'formula', u'entropy']\n",
        "For year 1999\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2241.25042755 0.0 49.5602351208\n",
        "2240.79591907 0.000240090253361 49.7074558555\n",
        "2240.38570689 0.000216599997518 49.854523252\n",
        "2240.01485961 0.000195738770155 50.0007955288\n",
        "2236.43965151 0.0764709364867 53.5941468949\n",
        "2236.14226488 0.00446316904875 54.5764617888\n",
        "2236.10846376"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.000427411312328 54.7080354392\n",
        "2236.10402422 5.75786822533e-05 54.7005695175\n",
        "2236.10339672 1.04026538189e-05 54.6944390643\n",
        "2236.10333567 1.03465111009e-06 54.6922599835\n",
        "2236.10333015 7.65665209061e-08 54.692761716\n",
        "2236.10332928"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.10509157388e-08 54.6927690936\n",
        "2236.10332918 1.63170817485e-09 54.6928517471\n",
        "2236.10332916 1.87468407094e-10 54.6928645373\n",
        "2236.10332916 1.17648761758e-11 54.6928665907\n",
        "2236.10332916 2.08133430638e-12 54.6928650205\n",
        "2236.10332916 2.0220653128e-13 54.6928638519\n",
        "2236.10332916"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.20525694698e-16 54.692863891\n",
        "2236.10332916 2.93937412209e-14 54.6928645106\n",
        "2236.10332916 6.68033575988e-17 54.6928644967\n",
        "IHT Keywords\n",
        "[u'projection', u'quantization', u'explain', u'heterotic', u'thermal', u'gauge', u'mechanics', u'torus', u'limit', u'satisfied', u'numerical', u'correction', u'common', u'strength', u'slightly', u'sitter', u'assumption', u'component', u'source', u'essential']\n",
        "For year 2000\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2250.42854871 0.0 48.1062417826\n",
        "2249.90829811 0.000276489893926 48.2402838767\n",
        "2249.4494128 0.000243537574834 48.3773282659\n",
        "2249.04246536 0.000215709981114 48.5161158463\n",
        "2245.65510927 0.0632595373107 51.5550192294\n",
        "2245.11072166 0.00727919826743 52.9394166328\n",
        "2245.03180834"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.000996953761563 53.2933892567\n",
        "2245.01744151 0.000226389060057 53.3102799582\n",
        "2245.01591106 2.5204488248e-05 53.2845924248\n",
        "2245.01580305 1.57259669331e-06 53.2785811112\n",
        "2245.01578862 1.98203794561e-07 53.2790949222\n",
        "2245.0157866 3.10102688649e-08 53.2795656636\n",
        "2245.01578642"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.8616340579e-09 53.2796631627\n",
        "2245.0157864 3.04224373505e-10 53.2796484618\n",
        "2245.0157864 3.33644613086e-11 53.2796367861\n",
        "2245.0157864 3.93784399501e-12 53.2796323361\n",
        "2245.0157864 1.27744396179e-12 53.2796301108\n",
        "2245.0157864 5.84348844086e-14 53.2796306444\n",
        "2245.0157864"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.0968344384e-17 53.2796306338\n",
        "IHT Keywords\n",
        "[u'form', u'domain', u'discrete', u'appearance', u'equivalence', u'untwisted', u'type', u'naturally', u'mirror', u'effectively', u'boundary', u'frame', u'breaking', u'alternative', u'argument', u'variation', u'pair', u'ordinary', u'dependent', u'classes']\n",
        "For year 2001\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2225.7088166 0.0 51.1311664782\n",
        "2225.29176327 0.000221596363853 51.2448253215\n",
        "2224.92378714 0.000195303752793 51.3597738075\n",
        "2224.59771513 0.000172894313447 51.4751317539\n",
        "2221.9354146 0.0488458489522 53.906274449\n",
        "2221.59198221"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00439204372558 54.8483048456\n",
        "2221.52978259 0.000939891104855 55.1294025254\n",
        "2221.52343645 0.000101351422728 55.1438534874\n",
        "2221.52242871 1.60367760379e-05 55.1333385477\n",
        "2221.52233022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.49724335511e-06 55.1279337789\n",
        "2221.52232045 1.46040361108e-07 55.1289861852\n",
        "2221.52231921 1.6880233318e-08 55.1293471931\n",
        "2221.52231907 2.02744929768e-09 55.1295276675\n",
        "2221.52231905 3.09094390649e-10 55.129579488\n",
        "2221.52231905"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.44354401443e-11 55.129575558\n",
        "2221.52231905 3.55192287286e-12 55.1295879751\n",
        "2221.52231905 3.07583514726e-13 55.1295888568\n",
        "2221.52231905 3.00894014639e-14 55.1295896536\n",
        "2221.52231905"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.69761263439e-17 55.1295896843\n",
        "IHT Keywords\n",
        "[u'noncommutative', u'fractional', u'flow', u'tension', u'relativistic', u'irreducible', u'derivative', u'bulk', u'unstable', u'sphere', u'wrapped', u'correspondence', u'exact', u'study', u'research', u'invariant', u'split', u'calculation', u'bounded', u'multiplet']\n",
        "For year 2002\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2236.37993667 0.0 50.3147540522\n",
        "2235.84208963 0.000285175744671 50.5283502748\n",
        "2235.36370637 0.000253449727328 50.7397167239\n",
        "2234.93691163 0.000225958818548 50.9480316238\n",
        "2231.27268514 0.0704057335365 55.2305542525\n",
        "2230.85327192 0.00581069771168 56.5908721579\n",
        "2230.79875631 0.00071229638114 56.8225632969\n",
        "2230.78897012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00014349828683 56.8270085253\n",
        "2230.78746125 2.34189078425e-05 56.7896258168\n",
        "2230.78722121 3.71683345255e-06 56.7836911725\n",
        "2230.78719056 4.76166731772e-07 56.7836479603\n",
        "2230.78718686 5.58459713258e-08 56.7834646057\n",
        "2230.78718638"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.05825014104e-09 56.7834058281\n",
        "2230.78718631 1.045886961e-09 56.7833850875\n",
        "2230.78718631 1.39994982012e-10 56.7833834082\n",
        "2230.78718631 1.21288560953e-11 56.7833768892\n",
        "2230.78718631 1.22147264724e-12 56.7833743469\n",
        "2230.78718631"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.52325278732e-14 56.7833744664\n",
        "2230.78718631 4.88872956952e-17 56.7833744857\n",
        "IHT Keywords\n",
        "[u'bulk', u'deformation', u'multiple', u'commutative', u'discussion', u'ratio', u'main', u'stationary', u'established', u'cosmological', u'exist', u'cubic', u'ghost', u'assumed', u'version', u'variation', u'annihilation', u'contrast', u'geometry', u'method']\n",
        "For year 2003\n",
        "('Number of documents', 2400)\n",
        "('Number of times query appears in all documents: ', 200)\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2231.23116735 0.0 51.1002705062\n",
        "2230.77083731 0.000244464969657 51.0595985206\n",
        "2230.36405496 0.000215850789269 51.0318663075\n",
        "2230.00342972 0.00019121607626 51.0152743898\n",
        "2227.0784308 0.0533405641125 51.3686949517\n",
        "2226.73379912 0.0048270169061 52.4836894342\n",
        "2226.67480769 0.000776065456694 52.8187894382\n",
        "2226.6655502"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.000158639656072 52.8631432914\n",
        "2226.66442889 1.93653263671e-05 52.8663390913\n",
        "2226.66429949 1.95189623736e-06 52.8667844286\n",
        "2226.66428532 2.18249930722e-07 52.8677439781\n",
        "2226.66428363 2.38354310294e-08 52.8675443704\n",
        "2226.66428342"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.21404651206e-09 52.8674123858\n",
        "2226.66428339 5.1394311315e-10 52.8673804114\n",
        "2226.66428338 4.82240572053e-11 52.8673704278\n",
        "2226.66428338 4.48254380852e-12 52.8673647827\n",
        "2226.66428338 4.16665306634e-13 52.8673623655\n",
        "2226.66428338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6.40137158556e-14 52.8673615597\n",
        "2226.66428338 3.80979120344e-15 52.8673615321\n",
        "2226.66428338 2.16029327757e-17 52.8673615069\n",
        "IHT Keywords\n",
        "[u'behavior', u'decay', u'alternative', u'stability', u'sitter', u'series', u'upper', u'plane', u'torus', u'express', u'imaginary', u'oscillator', u'algebra', u'entropy', u'avoid', u'extra', u'technique', u'noncommutative', u'file', u'homogeneous']\n"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}